# Smart Assist: YOLO-Based Object Detection for the Visually Impaired

## ğŸ“Œ Project Overview
**Vision Partner** is an AI-powered assistive system that helps visually impaired individuals navigate their surroundings. It uses **YOLO (You Only Look Once) object detection** to recognize objects in real-time and provides **audio feedback** to the user. This project enhances independent mobility and accessibility through the integration of **computer vision and text-to-speech (TTS) technologies**.

## ğŸš€ Features
- ğŸ¯ **Real-time object detection** using YOLOv4/YOLOv5  
- ğŸ”Š **Audio feedback** via Text-to-Speech (TTS)  
- ğŸ¥ **Live camera feed processing**  
- ğŸ“ **Distance estimation** (optional for enhanced safety)  
- ğŸ—ï¸ **Portable & lightweight model** for real-world deployment  

## ğŸ› ï¸ Technologies Used
- **Deep Learning** â€“ YOLO (You Only Look Once)  
- **Python** â€“ OpenCV, TensorFlow/PyTorch  
- **Computer Vision** â€“ Real-time image processing  
- **Text-to-Speech (TTS)** â€“ gTTS or Google Cloud TTS  

## ğŸ“¥ Installation & Setup
### 1ï¸âƒ£ Clone the Repository  
```bash
git clone https://github.com/Thiru-1820/Object_detection-using-Yolov10-.git
cd Object_detection-using-Yolov10
python object_detection.py (only for object detections)
python object_detection_distance.py (object detection with distancd)
python object_detection_distance_tts.py 
